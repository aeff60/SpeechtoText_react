{"ast":null,"code":"import _toConsumableArray from\"C:\\\\Users\\\\Aeff\\\\Desktop\\\\sandboxProject\\\\voiceTextTut\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/esm/toConsumableArray\";import _slicedToArray from\"C:\\\\Users\\\\Aeff\\\\Desktop\\\\sandboxProject\\\\voiceTextTut\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/esm/slicedToArray\";import React,{useState,useEffect}from'react';import'./App.css';var SpeechRecognition=window.SpeechRecognition||window.webkitSpeechRecognition;var mic=new SpeechRecognition();mic.continuous=true;mic.interimResults=true;mic.lang='th-TH';function App(){var _useState=useState(false),_useState2=_slicedToArray(_useState,2),isListening=_useState2[0],setIsListening=_useState2[1];var _useState3=useState(null),_useState4=_slicedToArray(_useState3,2),note=_useState4[0],setNote=_useState4[1];var _useState5=useState([]),_useState6=_slicedToArray(_useState5,2),savedNotes=_useState6[0],setSavedNotes=_useState6[1];useEffect(function(){handleListen();},[isListening]);var handleListen=function handleListen(){if(isListening){mic.start();mic.onend=function(){console.log('continue..');mic.start();};}else{mic.stop();mic.onend=function(){console.log('Stopped Mic on Click');};}mic.onstart=function(){console.log('Mics on');};mic.onresult=function(event){var transcript=Array.from(event.results).map(function(result){return result[0];}).map(function(result){return result.transcript;}).join('');console.log(transcript);setNote(transcript);mic.onerror=function(event){console.log(event.error);};};};var handleSaveNote=function handleSaveNote(){setSavedNotes([].concat(_toConsumableArray(savedNotes),[note]));setNote('');};return/*#__PURE__*/React.createElement(React.Fragment,null,/*#__PURE__*/React.createElement(\"h1\",null,\"Voice Notes\"),/*#__PURE__*/React.createElement(\"div\",{className:\"container\"},/*#__PURE__*/React.createElement(\"div\",{className:\"box\"},/*#__PURE__*/React.createElement(\"h2\",null,\"Current Note\"),isListening?/*#__PURE__*/React.createElement(\"span\",null,\"\\uD83C\\uDF99\\uFE0F\"):/*#__PURE__*/React.createElement(\"span\",null,\"\\uD83D\\uDED1\\uD83C\\uDF99\\uFE0F\"),/*#__PURE__*/React.createElement(\"button\",{onClick:handleSaveNote,disabled:!note},\"Save Note\"),/*#__PURE__*/React.createElement(\"button\",{onClick:function onClick(){return setIsListening(function(prevState){return!prevState;});}},\"Start/Stop\"),/*#__PURE__*/React.createElement(\"p\",null,note)),/*#__PURE__*/React.createElement(\"div\",{className:\"box\"},/*#__PURE__*/React.createElement(\"h2\",null,\"Notes\"),savedNotes.map(function(n){return/*#__PURE__*/React.createElement(\"p\",{key:n},n);}))));}export default App;","map":{"version":3,"sources":["C:/Users/Aeff/Desktop/sandboxProject/voiceTextTut/src/App.js"],"names":["React","useState","useEffect","SpeechRecognition","window","webkitSpeechRecognition","mic","continuous","interimResults","lang","App","isListening","setIsListening","note","setNote","savedNotes","setSavedNotes","handleListen","start","onend","console","log","stop","onstart","onresult","event","transcript","Array","from","results","map","result","join","onerror","error","handleSaveNote","prevState","n"],"mappings":"4WAAA,MAAOA,CAAAA,KAAP,EAAgBC,QAAhB,CAA0BC,SAA1B,KAA2C,OAA3C,CACA,MAAO,WAAP,CAEA,GAAMC,CAAAA,iBAAiB,CACrBC,MAAM,CAACD,iBAAP,EAA4BC,MAAM,CAACC,uBADrC,CAEA,GAAMC,CAAAA,GAAG,CAAG,GAAIH,CAAAA,iBAAJ,EAAZ,CAEAG,GAAG,CAACC,UAAJ,CAAiB,IAAjB,CACAD,GAAG,CAACE,cAAJ,CAAqB,IAArB,CACAF,GAAG,CAACG,IAAJ,CAAW,OAAX,CAEA,QAASC,CAAAA,GAAT,EAAe,eACyBT,QAAQ,CAAC,KAAD,CADjC,wCACNU,WADM,eACOC,cADP,8BAEWX,QAAQ,CAAC,IAAD,CAFnB,yCAENY,IAFM,eAEAC,OAFA,8BAGuBb,QAAQ,CAAC,EAAD,CAH/B,yCAGNc,UAHM,eAGMC,aAHN,eAKbd,SAAS,CAAC,UAAM,CACde,YAAY,GACb,CAFQ,CAEN,CAACN,WAAD,CAFM,CAAT,CAIA,GAAMM,CAAAA,YAAY,CAAG,QAAfA,CAAAA,YAAe,EAAM,CACzB,GAAIN,WAAJ,CAAiB,CACfL,GAAG,CAACY,KAAJ,GACAZ,GAAG,CAACa,KAAJ,CAAY,UAAM,CAChBC,OAAO,CAACC,GAAR,CAAY,YAAZ,EACAf,GAAG,CAACY,KAAJ,GACD,CAHD,CAID,CAND,IAMO,CACLZ,GAAG,CAACgB,IAAJ,GACAhB,GAAG,CAACa,KAAJ,CAAY,UAAM,CAChBC,OAAO,CAACC,GAAR,CAAY,sBAAZ,EACD,CAFD,CAGD,CACDf,GAAG,CAACiB,OAAJ,CAAc,UAAM,CAClBH,OAAO,CAACC,GAAR,CAAY,SAAZ,EACD,CAFD,CAIAf,GAAG,CAACkB,QAAJ,CAAe,SAAAC,KAAK,CAAI,CACtB,GAAMC,CAAAA,UAAU,CAAGC,KAAK,CAACC,IAAN,CAAWH,KAAK,CAACI,OAAjB,EAChBC,GADgB,CACZ,SAAAC,MAAM,QAAIA,CAAAA,MAAM,CAAC,CAAD,CAAV,EADM,EAEhBD,GAFgB,CAEZ,SAAAC,MAAM,QAAIA,CAAAA,MAAM,CAACL,UAAX,EAFM,EAGhBM,IAHgB,CAGX,EAHW,CAAnB,CAIAZ,OAAO,CAACC,GAAR,CAAYK,UAAZ,EACAZ,OAAO,CAACY,UAAD,CAAP,CACApB,GAAG,CAAC2B,OAAJ,CAAc,SAAAR,KAAK,CAAI,CACrBL,OAAO,CAACC,GAAR,CAAYI,KAAK,CAACS,KAAlB,EACD,CAFD,CAGD,CAVD,CAWD,CA5BD,CA8BA,GAAMC,CAAAA,cAAc,CAAG,QAAjBA,CAAAA,cAAiB,EAAM,CAC3BnB,aAAa,8BAAKD,UAAL,GAAiBF,IAAjB,GAAb,CACAC,OAAO,CAAC,EAAD,CAAP,CACD,CAHD,CAKA,mBACE,qDACE,4CADF,cAEE,2BAAK,SAAS,CAAC,WAAf,eACE,2BAAK,SAAS,CAAC,KAAf,eACE,6CADF,CAEGH,WAAW,cAAG,qDAAH,cAAsB,iEAFpC,cAGE,8BAAQ,OAAO,CAAEwB,cAAjB,CAAiC,QAAQ,CAAE,CAACtB,IAA5C,cAHF,cAME,8BAAQ,OAAO,CAAE,yBAAMD,CAAAA,cAAc,CAAC,SAAAwB,SAAS,QAAI,CAACA,SAAL,EAAV,CAApB,EAAjB,eANF,cASE,6BAAIvB,IAAJ,CATF,CADF,cAYE,2BAAK,SAAS,CAAC,KAAf,eACE,sCADF,CAEGE,UAAU,CAACe,GAAX,CAAe,SAAAO,CAAC,qBACf,yBAAG,GAAG,CAAEA,CAAR,EAAYA,CAAZ,CADe,EAAhB,CAFH,CAZF,CAFF,CADF,CAwBD,CACD,cAAe3B,CAAAA,GAAf","sourcesContent":["import React, { useState, useEffect } from 'react'\r\nimport './App.css'\r\n\r\nconst SpeechRecognition =\r\n  window.SpeechRecognition || window.webkitSpeechRecognition\r\nconst mic = new SpeechRecognition()\r\n\r\nmic.continuous = true\r\nmic.interimResults = true\r\nmic.lang = 'th-TH'\r\n\r\nfunction App() {\r\n  const [isListening, setIsListening] = useState(false)\r\n  const [note, setNote] = useState(null)\r\n  const [savedNotes, setSavedNotes] = useState([])\r\n\r\n  useEffect(() => {\r\n    handleListen()\r\n  }, [isListening])\r\n\r\n  const handleListen = () => {\r\n    if (isListening) {\r\n      mic.start()\r\n      mic.onend = () => {\r\n        console.log('continue..')\r\n        mic.start()\r\n      }\r\n    } else {\r\n      mic.stop()\r\n      mic.onend = () => {\r\n        console.log('Stopped Mic on Click')\r\n      }\r\n    }\r\n    mic.onstart = () => {\r\n      console.log('Mics on')\r\n    }\r\n\r\n    mic.onresult = event => {\r\n      const transcript = Array.from(event.results)\r\n        .map(result => result[0])\r\n        .map(result => result.transcript)\r\n        .join('')\r\n      console.log(transcript)\r\n      setNote(transcript)\r\n      mic.onerror = event => {\r\n        console.log(event.error)\r\n      }\r\n    }\r\n  }\r\n\r\n  const handleSaveNote = () => {\r\n    setSavedNotes([...savedNotes, note])\r\n    setNote('')\r\n  }\r\n\r\n  return (\r\n    <>\r\n      <h1>Voice Notes</h1>\r\n      <div className=\"container\">\r\n        <div className=\"box\">\r\n          <h2>Current Note</h2>\r\n          {isListening ? <span>ğŸ™ï¸</span> : <span>ğŸ›‘ğŸ™ï¸</span>}\r\n          <button onClick={handleSaveNote} disabled={!note}>\r\n            Save Note\r\n          </button>\r\n          <button onClick={() => setIsListening(prevState => !prevState)}>\r\n            Start/Stop\r\n          </button>\r\n          <p>{note}</p>\r\n        </div>\r\n        <div className=\"box\">\r\n          <h2>Notes</h2>\r\n          {savedNotes.map(n => (\r\n            <p key={n}>{n}</p>\r\n          ))}\r\n        </div>\r\n      </div>\r\n    </>\r\n  )\r\n}\r\nexport default App"]},"metadata":{},"sourceType":"module"}